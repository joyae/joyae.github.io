---
layout: post
title: Attention
subtitle: Attention 이해하기
comments: true
tags: [study]
---

Attention 논문과 사람들의 페이퍼 리뷰를 읽어도 와닿지 않던 개념이   
이 [블로그 글](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)의 Visualization과 설명을 통해 아주 깨끗하게 이해되었다.
